{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "spark_path = '../../2016UCSD/255/spark-1.6.0-bin-hadoop2.6/'\n",
    "findspark.init(spark_path)\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local[3]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_features import *\n",
    "import os, pickle\n",
    "from sklearn import linear_model, datasets\n",
    "domain = 'random70'\n",
    "#domain = '100'\n",
    "train_file = 'Data/%s/trainData' % (domain)\n",
    "test_file = 'Data/%s/testData1' % (domain)\n",
    "\n",
    "pickled_trainX = 'trainX%s.pickle' % (domain)\n",
    "pickled_trainY = 'trainY%s.pickle' % (domain)\n",
    "pickled_testX = 'testX%s.pickle' % (domain)\n",
    "pickled_testY = 'testY%s.pickle' % (domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(infile):\n",
    "    lines = [ line for line in open(infile, 'r').readlines()]\n",
    "    text, trainY = [line.split(',')[0] for line in lines], \\\n",
    "                        [int(line.split(',')[1]) for line in lines]\n",
    "    wp = word_processor()\n",
    "    rdd = sc.parallelize(text).map(lambda x: wp.get_features1(x))\n",
    "    data = rdd.collect()\n",
    "    return [[d for d in data], trainY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(pickled_trainX) or not os.path.exists(pickled_trainY):\n",
    "    trainX, trainY = getData(train_file)\n",
    "    pickle.dump(trainX, open(pickled_trainX, 'w'))\n",
    "    pickle.dump(trainY, open(pickled_trainY, 'w'))\n",
    "else:\n",
    "    trainX = pickle.load(open(pickled_trainX, 'r'))\n",
    "    trainY = pickle.load(open(pickled_trainY, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pickled_testX) or not os.path.exists(pickled_testY):\n",
    "    testX, testY = getData(test_file)\n",
    "    pickle.dump(testX, open(pickled_testX, 'w'))\n",
    "    pickle.dump(testY, open(pickled_testY, 'w'))\n",
    "else:\n",
    "    testX = pickle.load(open(pickled_testX, 'r'))\n",
    "    testY = pickle.load(open(pickled_testY, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for x, y in zip(trainX, trainY):\n",
    "#     print x, y\n",
    "def model1(trainX, trainY, testX, testY):\n",
    "    logistic = linear_model.LogisticRegression(C=1e5)\n",
    "    #logistic = linear_model.LogisticRegression(C=10)\n",
    "    #logistic = linear_model.LogisticRegression(C = 1)\n",
    "    #print trainX.shape, trainY.shape\n",
    "    logistic.fit(trainX, trainY)\n",
    "    print 'score =', logistic.score(testX, testY)\n",
    "    return logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domain = 'random70_all'\n",
    "#domain = '100'\n",
    "train_file = 'testData/%s/trainData' % (domain)\n",
    "test_file = 'testData/%s/testData1' % (domain)\n",
    "\n",
    "pickled_trainX = 'trainX%s.pickle' % (domain)\n",
    "pickled_trainY = 'trainY%s.pickle' % (domain)\n",
    "pickled_testX = 'testX%s.pickle' % (domain)\n",
    "pickled_testY = 'testY%s.pickle' % (domain)\n",
    "if not os.path.exists(pickled_trainX) or not os.path.exists(pickled_trainY):\n",
    "    trainX, trainY = getData(train_file)\n",
    "    pickle.dump(trainX, open(pickled_trainX, 'w'))\n",
    "    pickle.dump(trainY, open(pickled_trainY, 'w'))\n",
    "else:\n",
    "    trainX = pickle.load(open(pickled_trainX, 'r'))\n",
    "    trainY = pickle.load(open(pickled_trainY, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(pickled_testX) or not os.path.exists(pickled_testY):\n",
    "    testX, testY = getData(test_file)\n",
    "    pickle.dump(testX, open(pickled_testX, 'w'))\n",
    "    pickle.dump(testY, open(pickled_testY, 'w'))\n",
    "else:\n",
    "    testX = pickle.load(open(pickled_testX, 'r'))\n",
    "    testY = pickle.load(open(pickled_testY, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
