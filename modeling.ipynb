{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# spark_path = '../../2016UCSD/255/spark-1.6.0-bin-hadoop2.6/'\n",
    "# findspark.init(spark_path)\n",
    "# from pyspark import SparkContext\n",
    "# sc = SparkContext(master=\"local[3]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_features import *\n",
    "import os, pickle\n",
    "from sklearn import linear_model, datasets\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(path, domain, model, emotion):\n",
    "    train_file = 'Data/%s/trainData.json' % (domain)\n",
    "    test_file = 'Data/%s/testData.json' % (domain)\n",
    "\n",
    "    pickled_trainX = '%s/%s/%s/%s/trainX.pickle' % (path, domain, model, emotion)\n",
    "    pickled_trainY = '%s/%s/%s/%s/trainY.pickle' % (path, domain, model, emotion)\n",
    "    pickled_testX = '%s/%s/%s/%s/testX.pickle' % (path, domain, model, emotion)\n",
    "    pickled_testY = '%s/%s/%s/%s/testY.pickle' % (path, domain, model, emotion)\n",
    "    \n",
    "    if not os.path.exists(pickled_trainX) or not os.path.exists(pickled_trainY):\n",
    "        trainX, trainY = get_json_data(train_file, emotion)\n",
    "        pickle.dump(trainX, open(pickled_trainX, 'w'))\n",
    "        pickle.dump(trainY, open(pickled_trainY, 'w'))\n",
    "    else:\n",
    "        trainX = pickle.load(open(pickled_trainX, 'r'))\n",
    "        trainY = pickle.load(open(pickled_trainY, 'r'))\n",
    "    if not os.path.exists(pickled_testX) or not os.path.exists(pickled_testY):\n",
    "        testX, testY = get_json_data(test_file, emotion)\n",
    "        pickle.dump(testX, open(pickled_testX, 'w'))\n",
    "        pickle.dump(testY, open(pickled_testY, 'w'))\n",
    "    else:\n",
    "        testX = pickle.load(open(pickled_testX, 'r'))\n",
    "        testY = pickle.load(open(pickled_testY, 'r'))\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14182\n",
      "14182\n"
     ]
    }
   ],
   "source": [
    "path, domain, model, emotion = 'pickled' , 'Semeval_2007', 'model1', 'sad'\n",
    "trainX, trainY, testX, testY = train_model(path, domain, model, emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 165) (250,)\n",
      "c, train score, test score,\n",
      "1e-05 0.616   0.709\n",
      "(250, 165) (250,)\n",
      "c, train score, test score,\n",
      "0.0001 0.616   0.709\n",
      "(250, 165) (250,)\n",
      "c, train score, test score,\n",
      "0.001 0.616   0.709\n",
      "(250, 165) (250,)\n",
      "c, train score, test score,\n",
      "0.01 0.616   0.713\n",
      "(250, 165) (250,)\n",
      "c, train score, test score,\n",
      "0.1 0.7   0.707\n",
      "(250, 165) (250,)\n",
      "c, train score, test score,\n",
      "1 0.704   0.682\n",
      "(250, 165) (250,)\n",
      "c, train score, test score,\n",
      "10 0.732   0.67\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    c = 10 ** (-5 + i)\n",
    "    logistic = model1(trainX, trainY, c = c)\n",
    "    print 'c, train score, test score,'\n",
    "    print c, evaluate(logistic, trainX, trainY), ' ', evaluate(logistic, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def getData(infile):\n",
    "#     lines = [ line for line in open(infile, 'r').readlines()]\n",
    "#     text, Y = [line.split(',')[0] for line in lines], \\\n",
    "#                         [int(line.split(',')[1]) for line in lines]\n",
    "#     print len(text), len(Y)\n",
    "#     assert(len(text) == len(Y), \"we've got a problem\")\n",
    "#     wp = word_processor()\n",
    "#     rdd = sc.parallelize(text).map(lambda x: wp.get_features1(x))\n",
    "#     data = rdd.collect()\n",
    "#     assert(len(data) == len(Y), \"we've got a problem2\")\n",
    "#     return [data, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistic = train_model(path, domain)\n",
    "# print 'train score, test score'\n",
    "# print evaluate(logistic, trainX, trainY), ' ', evaluate(logistic, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistic = train_model(trainX, trainY, c = 10)\n",
    "# print 'train score, test score'\n",
    "# print evaluate(logistic, trainX, trainY), ' ', evaluate(logistic, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## polarity with semeval-2017-task-5-subtask-1 data and TextBlob model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainFile = 'Data/polarity/trainData'\n",
    "testFile = 'Data/polarity/testData'\n",
    "trainData = [[ ''.join(line.split(',')[:-1]), float(line.strip('\\n').split(',')[-1]) > 0] for line in open(trainFile, 'r').readlines()]\n",
    "testData = [[ ''.join(line.split(',')[:-1]), float(line.strip('\\n').split(',')[-1]) > 0] for line in open(testFile, 'r').readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 578\n"
     ]
    }
   ],
   "source": [
    "print len(trainData), len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.498 0.506920415225\n"
     ]
    }
   ],
   "source": [
    "def evaluate(data):\n",
    "    pred = [TextBlob(d[0]).sentiment.polarity > 0 for d in data]\n",
    "    Y = [d[1] for d in data]\n",
    "    return np.sum(np.array(pred) == np.array(Y)) / float(len(data))\n",
    "print evaluate(trainData), evaluate(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
