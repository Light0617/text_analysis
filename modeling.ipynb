{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "spark_path = '../../2016UCSD/255/spark-1.6.0-bin-hadoop2.6/'\n",
    "findspark.init(spark_path)\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(master=\"local[3]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_features import *\n",
    "import os, pickle\n",
    "from sklearn import linear_model, datasets\n",
    "domain = 'random70'\n",
    "#domain = '100'\n",
    "train_file = 'Data/%s/trainData' % (domain)\n",
    "test_file = 'Data/%s/testData' % (domain)\n",
    "\n",
    "pickled_trainX = 'trainX%s.pickle' % (domain)\n",
    "pickled_trainY = 'trainY%s.pickle' % (domain)\n",
    "pickled_testX = 'testX%s.pickle' % (domain)\n",
    "pickled_testY = 'testY%s.pickle' % (domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-4e841e63d2ac>:5: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(text) == len(Y), \"we've got a problem\")\n",
      "<ipython-input-6-4e841e63d2ac>:9: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(data) == len(Y), \"we've got a problem2\")\n"
     ]
    }
   ],
   "source": [
    "def getData(infile):\n",
    "    lines = [ line for line in open(infile, 'r').readlines()]\n",
    "    text, Y = [line.split(',')[0] for line in lines], \\\n",
    "                        [int(line.split(',')[1]) for line in lines]\n",
    "    print len(text), len(Y)\n",
    "    assert(len(text) == len(Y), \"we've got a problem\")\n",
    "    wp = word_processor()\n",
    "    rdd = sc.parallelize(text).map(lambda x: wp.get_features1(x))\n",
    "    data = rdd.collect()\n",
    "    assert(len(data) == len(Y), \"we've got a problem2\")\n",
    "    return [data, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(pickled_testX) or not os.path.exists(pickled_testY):\n",
    "    testX, testY = getData(test_file)\n",
    "    pickle.dump(testX, open(pickled_testX, 'w'))\n",
    "    pickle.dump(testY, open(pickled_testY, 'w'))\n",
    "else:\n",
    "    testX = pickle.load(open(pickled_testX, 'r'))\n",
    "    testY = pickle.load(open(pickled_testY, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 1400\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(pickled_trainX) or not os.path.exists(pickled_trainY):\n",
    "    trainX, trainY = getData(train_file)\n",
    "    pickle.dump(trainX, open(pickled_trainX, 'w'))\n",
    "    pickle.dump(trainY, open(pickled_trainY, 'w'))\n",
    "else:\n",
    "    trainX = pickle.load(open(pickled_trainX, 'r'))\n",
    "    trainY = pickle.load(open(pickled_trainY, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for x, y in zip(trainX, trainY):\n",
    "#     print x, y\n",
    "def model1(trainX, trainY, testX, testY):\n",
    "    logistic = linear_model.LogisticRegression(C=1e5)\n",
    "    logistic = linear_model.LogisticRegression(C=10)\n",
    "    #logistic = linear_model.LogisticRegression(C = 1)\n",
    "    trainX, trainY, testX, testY = np.array(trainX), np.array(trainY), \\\n",
    "                                        np.array(testX), np.array(testY)\n",
    "    print trainX.shape, trainY.shape,testX.shape,testY.shape  \n",
    "    logistic.fit(trainX, trainY)\n",
    "    print 'train score =', 'test score' \n",
    "    print logistic.score(trainX, trainY), logistic.score(testX, testY)\n",
    "    return logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 165) (1400,) (600, 165) (600,)\n",
      "train score = test score\n",
      "0.612142857143 0.578333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 8982\n"
     ]
    }
   ],
   "source": [
    "domain = 'random70_all'\n",
    "#domain = '100'\n",
    "train_file = 'Data/%s/trainData' % (domain)\n",
    "test_file = 'Data/%s/testData' % (domain)\n",
    "\n",
    "pickled_trainX = 'trainX%s.pickle' % (domain)\n",
    "pickled_trainY = 'trainY%s.pickle' % (domain)\n",
    "pickled_testX = 'testX%s.pickle' % (domain)\n",
    "pickled_testY = 'testY%s.pickle' % (domain)\n",
    "if not os.path.exists(pickled_trainX) or not os.path.exists(pickled_trainY):\n",
    "    trainX, trainY = getData(train_file)\n",
    "    pickle.dump(trainX, open(pickled_trainX, 'w'))\n",
    "    pickle.dump(trainY, open(pickled_trainY, 'w'))\n",
    "else:\n",
    "    trainX = pickle.load(open(pickled_trainX, 'r'))\n",
    "    trainY = pickle.load(open(pickled_trainY, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3848 3848\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(pickled_testX) or not os.path.exists(pickled_testY):\n",
    "    testX, testY = getData(test_file)\n",
    "    pickle.dump(testX, open(pickled_testX, 'w'))\n",
    "    pickle.dump(testY, open(pickled_testY, 'w'))\n",
    "else:\n",
    "    testX = pickle.load(open(pickled_testX, 'r'))\n",
    "    testY = pickle.load(open(pickled_testY, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 165) (8982,) (3848, 165) (3848,)\n",
      "train score = test score\n",
      "0.591627699844 0.574324324324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
