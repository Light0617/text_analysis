{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import findspark\n",
    "# spark_path = '../../2016UCSD/255/spark-1.6.0-bin-hadoop2.6/'\n",
    "# findspark.init(spark_path)\n",
    "# from pyspark import SparkContext\n",
    "# sc = SparkContext(master=\"local[3]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_features import *\n",
    "import os, pickle\n",
    "from sklearn import linear_model, datasets\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(path, domain, model, emotion):\n",
    "    train_file = 'Data/%s/trainData.json' % (domain)\n",
    "    test_file = 'Data/%s/testData.json' % (domain)\n",
    "\n",
    "    pickled_trainX = '%s/%s/%s/%s/trainX.pickle' % (path, domain, model, emotion)\n",
    "    pickled_trainY = '%s/%s/%s/%s/trainY.pickle' % (path, domain, model, emotion)\n",
    "    pickled_testX = '%s/%s/%s/%s/testX.pickle' % (path, domain, model, emotion)\n",
    "    pickled_testY = '%s/%s/%s/%s/testY.pickle' % (path, domain, model, emotion)\n",
    "    \n",
    "    if not os.path.exists(pickled_trainX) or not os.path.exists(pickled_trainY):\n",
    "        trainX, trainY = get_json_data(train_file, emotion)\n",
    "        pickle.dump(trainX, open(pickled_trainX, 'w'))\n",
    "        pickle.dump(trainY, open(pickled_trainY, 'w'))\n",
    "    else:\n",
    "        trainX = pickle.load(open(pickled_trainX, 'r'))\n",
    "        trainY = pickle.load(open(pickled_trainY, 'r'))\n",
    "    if not os.path.exists(pickled_testX) or not os.path.exists(pickled_testY):\n",
    "        testX, testY = get_json_data(test_file, emotion)\n",
    "        pickle.dump(testX, open(pickled_testX, 'w'))\n",
    "        pickle.dump(testY, open(pickled_testY, 'w'))\n",
    "    else:\n",
    "        testX = pickle.load(open(pickled_testX, 'r'))\n",
    "        testY = pickle.load(open(pickled_testY, 'r'))\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "logistic\n",
      "(987, 166) (987,)\n",
      "precision  0.695533769063\n",
      "recall  0.644039976656\n",
      "0.701244813278\n"
     ]
    }
   ],
   "source": [
    "path, domain, model = 'pickled' , 'Semeval_2007', 'model1'\n",
    "emotion = 'sad'\n",
    "print emotion\n",
    "trainX, trainY, testX, testY = train_model(path, domain, model, emotion)\n",
    "c = 10 ** (2)\n",
    "classifier = model1(trainX, trainY, c = c, ml_model = 'logistic')\n",
    "#print c, compare(classifier, trainX, trainY)\n",
    "print evaluate(classifier, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================\n",
      "joy\n",
      "logistic\n",
      "(987, 166) (987,)\n",
      "======\n",
      "c, train score, test score,\n",
      "10\n",
      "precision  0.616421568627\n",
      "recall  0.60817805383\n",
      "0.614107883817\n",
      "=======================\n",
      "sad\n",
      "logistic\n",
      "(987, 166) (987,)\n",
      "======\n",
      "c, train score, test score,\n",
      "10\n",
      "precision  0.702780008029\n",
      "recall  0.647395681354\n",
      "0.705394190871\n",
      "=======================\n",
      "disgust\n",
      "logistic\n",
      "(987, 166) (987,)\n",
      "======\n",
      "c, train score, test score,\n",
      "10\n",
      "precision  0.630594135802\n",
      "recall  0.618788601909\n",
      "0.639004149378\n",
      "=======================\n",
      "anger\n",
      "logistic\n",
      "(987, 166) (987,)\n",
      "======\n",
      "c, train score, test score,\n",
      "10\n",
      "precision  0.654225255032\n",
      "recall  0.655771372877\n",
      "0.655601659751\n",
      "=======================\n",
      "surprise\n",
      "logistic\n",
      "(987, 166) (987,)\n",
      "======\n",
      "c, train score, test score,\n",
      "10\n",
      "precision  0.286307053942\n",
      "recall  0.5\n",
      "0.572614107884\n",
      "=======================\n",
      "fear\n",
      "logistic\n",
      "(987, 166) (987,)\n",
      "======\n",
      "c, train score, test score,\n",
      "10\n",
      "precision  0.67057591623\n",
      "recall  0.612236461348\n",
      "0.618257261411\n"
     ]
    }
   ],
   "source": [
    "#joy, sad, disgust, anger, surprise, fear\n",
    "path, domain, model = 'pickled' , 'Semeval_2007', 'model1'\n",
    "for emotion in ['joy', 'sad', 'disgust', 'anger', 'surprise', 'fear']:\n",
    "    print '======================='\n",
    "    print emotion\n",
    "    trainX, trainY, testX, testY = train_model(path, domain, model, emotion)\n",
    "    for i in[1]:\n",
    "        c = 10 ** (i)\n",
    "        classifier = model1(trainX, trainY, c = c, ml_model = 'logistic')\n",
    "        print '======'\n",
    "        print 'c, train score, test score,'\n",
    "        print c\n",
    "        #print evaluate(classifier, trainX, trainY)\n",
    "        print  evaluate(classifier, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## polarity with semeval-2017-task-5-subtask-1 data and TextBlob model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainFile = 'Data/polarity/trainData'\n",
    "testFile = 'Data/polarity/testData'\n",
    "trainData = [[ ''.join(line.split(',')[:-1]), float(line.strip('\\n').split(',')[-1]) > 0] for line in open(trainFile, 'r').readlines()]\n",
    "testData = [[ ''.join(line.split(',')[:-1]), float(line.strip('\\n').split(',')[-1]) > 0] for line in open(testFile, 'r').readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(trainData), len(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate(data):\n",
    "    pred = [TextBlob(d[0]).sentiment.polarity > 0 for d in data]\n",
    "    Y = [d[1] for d in data]\n",
    "    return np.sum(np.array(pred) == np.array(Y)) / float(len(data))\n",
    "print evaluate(trainData), evaluate(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
